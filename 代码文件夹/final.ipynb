{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python352\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "d:\\python\\python352\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import preprocessing \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket  \n",
       "0       3    male      1       0.0         A/5 21171  \n",
       "1       1  female      1       1.0          PC 17599  \n",
       "2       3  female      0       1.0  STON/O2. 3101282  \n",
       "3       1  female      1       1.0            113803  \n",
       "4       3    male      0       0.0            373450  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据并且把所有数据结合到一起\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "passengerId=test_data['PassengerId']\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对全部集合进行处理的函数\n",
    "def  clean_data(df):\n",
    "    # 替换称谓 \n",
    "    df['Title'] = df['Name'].str.extract('.+,(.+)', expand=False).str.extract('^(.+?)\\.', expand=False).str.strip()\n",
    "    df['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer' , inplace = True)\n",
    "    df['Title'].replace(['Jonkheer','Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty' , inplace = True)\n",
    "    df['Title'].replace(['Mme', 'Ms', 'Mrs'], 'Mrs' , inplace = True)\n",
    "    df['Title'].replace(['Mlle', 'Miss'], 'Miss' , inplace = True)\n",
    "    df['Title'].replace(['Mr'], 'Mr' , inplace = True)\n",
    "    df['Title'].replace(['Master'], 'Master' , inplace = True)\n",
    "    \n",
    "    #用随机森林预测年龄\n",
    "    age_df = df[['Age', 'Pclass','Sex','Title']]\n",
    "    age_df = pd.get_dummies(age_df)\n",
    "    known_age = age_df[age_df.Age.notnull()].as_matrix()\n",
    "    unknown_age = age_df[age_df.Age.isnull()].as_matrix()\n",
    "    y = known_age[:, 0]\n",
    "    X = known_age[:, 1:]\n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=100, n_jobs=-1)\n",
    "    rfr.fit(X, y)\n",
    "    predictedAges = rfr.predict(unknown_age[:, 1::])\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "#     #放大年龄的影响，增加孩子属性，年龄小于16岁均视为孩子\n",
    "#     df['Child'] = df['Age'].apply(lambda x: 1 if x < 16 else 0)\n",
    "    \n",
    "    #Embarked用众数S代替空值\n",
    "    df['Embarked'] = df['Embarked'].fillna('S')\n",
    "    \n",
    "    #Fare缺失量为1，缺失Fare信息的乘客的Embarked为S，Pclass为3 用这个分组平均数填充\n",
    "    fare_mean = df[(df['Embarked'] == \"S\") & (df['Pclass'] == 3)].Fare.mean()\n",
    "    df['Fare']=df['Fare'].fillna(fare_mean)\n",
    "    \n",
    "    #对Cabin进行处理,提取首字母\n",
    "    df['Cabin'] = df['Cabin'].apply(lambda x:str(x)[0] if pd.notnull(x) else 'U')\n",
    "    \n",
    "    #增加家庭规模属性\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    #在1到3范围内存活率最高赋值2 大于6存活率最低赋值0\n",
    "    df['Family'] = df['FamilySize'].apply(lambda x: 0 if x > 6 else (2 if x >=1 and x <=3 else 1))\n",
    "    \n",
    "    \n",
    "    #新增TicketGroup特征，统计每个乘客的共票号数。\n",
    "    Ticket_Count = dict(df['Ticket'].value_counts())\n",
    "    df['TicketGroup'] = df['Ticket'].apply(lambda x:Ticket_Count[x])\n",
    "    #同Family\n",
    "    df['TicketGroup'] = df['TicketGroup'].apply(lambda x: 0 if x > 8 else (2 if x >=2 and x <=4 else 1))\n",
    "    \n",
    "    #把姓氏相同的乘客划分为同一组，从人数大于一的组中分别提取出每组的妇女儿童和成年男性\n",
    "    df['Surname']=df['Name'].apply(lambda x:x.split(',')[0].strip())\n",
    "    Surname_Count = dict(df['Surname'].value_counts())\n",
    "    df['FamilyGroup'] = df['Surname'].apply(lambda x:Surname_Count[x])\n",
    "    Female_Child_Group=df.loc[(df['Family']>=2) & ((df['Age']<=12) | (df['Sex']=='female'))]\n",
    "    Male_Adult_Group=df.loc[(df['Family']>=2) & (all_data['Age']>12) & (all_data['Sex']=='male')]\n",
    "    \n",
    "    #因为普遍规律是女性和儿童幸存率高，成年男性幸存较低，所以我们把不符合普遍规律的反常组选出来单独处理。把女性和儿童组中幸存率为0的组设置为遇难组，把成年男性组中存活率为1的设置为幸存组，推测处于遇难组的女性和儿童幸存的可能性较低，处于幸存组的成年男性幸存的可能性较高。\n",
    "    Female_Child_Group = Female_Child_Group.groupby('Surname')['Survived'].mean()\n",
    "    Dead_List=set(Female_Child_Group[Female_Child_Group.apply(lambda x:x==0)].index)\n",
    "    Male_Adult_List=Male_Adult_Group.groupby('Surname')['Survived'].mean()\n",
    "    Survived_List=set(Male_Adult_List[Male_Adult_List.apply(lambda x:x==1)].index)\n",
    "\n",
    "    #为了使处于这两种反常组中的样本能够被正确分类，对测试集中处于反常组中的样本的Age，Title，Sex进行惩罚修改。\n",
    "    train=all_data.loc[all_data['Survived'].notnull()]\n",
    "    test=all_data.loc[all_data['Survived'].isnull()]\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Sex'] = 'male'\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Age'] = 60\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Title'] = 'Mr'\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Sex'] = 'female'\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Age'] = 5\n",
    "    test.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Title'] = 'Miss'\n",
    "    \n",
    "    df = pd.concat([train, test])\n",
    "    \n",
    "        \n",
    "    #对连续数据进行标准化处理\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    df['Fare'] = scaler.fit_transform(df.filter(['Fare']))\n",
    "    df['Age'] = scaler.fit_transform(df.filter(['Age']))\n",
    "\n",
    "    #drop掉无用属性\n",
    "    df = df.drop(['PassengerId'], axis=1)\n",
    "    df = df.drop(['Ticket'], axis=1)\n",
    "    df = df.drop(['FamilySize'], axis=1)\n",
    "    df = df.drop(['Parch'], axis=1)\n",
    "    df = df.drop(['SibSp'], axis=1)\n",
    "    df = df.drop(['Name'], axis=1)\n",
    "    df = df.drop(['Surname'], axis=1)\n",
    "    df = df.drop(['FamilyGroup'], axis=1)\n",
    "\n",
    "    #独热编码\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python352\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Family</th>\n",
       "      <th>TicketGroup</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.557449</td>\n",
       "      <td>-0.503291</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613673</td>\n",
       "      <td>0.734744</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.264668</td>\n",
       "      <td>-0.490240</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394088</td>\n",
       "      <td>0.383184</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.394088</td>\n",
       "      <td>-0.487823</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass  Survived  Family  TicketGroup  Cabin_A  \\\n",
       "0 -0.557449 -0.503291       3       0.0       2            1        0   \n",
       "1  0.613673  0.734744       1       1.0       2            2        0   \n",
       "2 -0.264668 -0.490240       3       1.0       1            1        0   \n",
       "3  0.394088  0.383184       1       1.0       2            2        0   \n",
       "4  0.394088 -0.487823       3       0.0       1            1        0   \n",
       "\n",
       "   Cabin_B  Cabin_C  Cabin_D      ...        Embarked_Q  Embarked_S  \\\n",
       "0        0        0        0      ...                 0           1   \n",
       "1        0        1        0      ...                 0           0   \n",
       "2        0        0        0      ...                 0           1   \n",
       "3        0        1        0      ...                 0           1   \n",
       "4        0        0        0      ...                 0           1   \n",
       "\n",
       "   Sex_female  Sex_male  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0           0         1             0           0         1          0   \n",
       "1           1         0             0           0         0          1   \n",
       "2           1         0             0           1         0          0   \n",
       "3           1         0             0           0         0          1   \n",
       "4           0         1             0           0         1          0   \n",
       "\n",
       "   Title_Officer  Title_Royalty  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = clean_data(all_data)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\python352\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train=all_data[all_data['Survived'].notnull()]\n",
    " #不知道为什么 Survived变成了float 需要换成int\n",
    "train['Survived'] = train['Survived'].apply(lambda x:int(x))\n",
    "test=all_data[all_data['Survived'].isnull()].drop('Survived',axis=1)\n",
    "train_data_X = train.drop(['Survived'],axis=1)\n",
    "train_data_Y = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe=Pipeline([('select',SelectKBest(k=20)), \n",
    "#                ('classify', RandomForestClassifier(random_state = 10, max_features = 'sqrt'))])\n",
    "\n",
    "# param_test = {'classify__n_estimators':list(range(20,50,2)), \n",
    "#               'classify__max_depth':list(range(3,60,3))}\n",
    "# gsearch = GridSearchCV(estimator = pipe, param_grid = param_test, scoring='roc_auc', cv=10)\n",
    "# gsearch.fit(train_data_X, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534031413612565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#交叉验证\n",
    "select = SelectKBest(k = 20)\n",
    "clf = RandomForestClassifier(random_state = 10, warm_start = True, \n",
    "                                  n_estimators = 26,\n",
    "                                  max_depth = 6, \n",
    "                                  max_features = 'sqrt')\n",
    "pipeline = make_pipeline(select, clf)\n",
    "pipeline.fit(train_data_X[:700], train_data_Y[:700])\n",
    "predictions = pipeline.predict(train_data_X[700:])\n",
    "fail_values = train_data_Y[700:] - predictions\n",
    "accuracy = fail_values.value_counts()[0]/len(fail_values)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('selectkbest', SelectKBest(k=20, score_func=<function f_classif at 0x000002BC6A20AD90>)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decreas...estimators=26, n_jobs=1,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = SelectKBest(k = 20)\n",
    "clf = RandomForestClassifier(random_state = 10, warm_start = True, \n",
    "                                  n_estimators = 26,\n",
    "                                  max_depth = 6, \n",
    "                                  max_features = 'sqrt')\n",
    "pipeline = make_pipeline(select, clf)\n",
    "pipeline.fit(train_data_X, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(test)\n",
    "submission = pd.DataFrame({\"PassengerId\": passengerId, \"Survived\": predictions.astype(np.int32)})\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
